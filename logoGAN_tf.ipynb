{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_GNVjr34myhw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import scipy.misc\n",
    "from helpers.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bMulCZyoeM9g"
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH, CHANNEL = 128, 128, 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5000\n",
    "version = 'new_logo'\n",
    "new_logo_path = './' + version\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mnCxVT1LeM9s"
   },
   "outputs": [],
   "source": [
    "def lrelu (x, n, leak = 0.2):#leaky relu activation function\n",
    "    return tf.maximum(x, leak*x, name = n)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1527432468587,
     "user": {
      "displayName": "Milos Mladenovic",
      "photoUrl": "//lh6.googleusercontent.com/-dA-JXATW86A/AAAAAAAAAAI/AAAAAAAAc6Q/qx8-ALBybj0/s50-c-k-no/photo.jpg",
      "userId": "102493204324592635873"
     },
     "user_tz": -120
    },
    "id": "qFChLwtly-1m",
    "outputId": "c6e07043-69c1-4ebc-c12b-39d4fc3783a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4867"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "logos_dir = os.path.join(current_dir, 'data/resized_data_128')\n",
    "\n",
    "images = []\n",
    "for each in os.listdir(logos_dir):\n",
    "    images.append(os.path.join(logos_dir, each))\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XYs6AmSeeM94"
   },
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    current_dir = os.getcwd()\n",
    "    logos_dir = os.path.join(current_dir, 'data/resized_data_128')\n",
    "    \n",
    "    images = []\n",
    "    for each in os.listdir(logos_dir):\n",
    "        images.append(os.path.join(logos_dir, each))\n",
    "    all_images = tf.convert_to_tensor(images, dtype = tf.string)    \n",
    "    \n",
    "    images_queue = tf.train.slice_input_producer([all_images])\n",
    "    content = tf.read_file(images_queue[0])\n",
    "    image = tf.image.decode_jpeg(content, channels = CHANNEL)\n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta = 0.1)\n",
    "    image = tf.image.random_contrast(image, lower = 0.9, upper = 1.1)\n",
    "    \n",
    "    size = [HEIGHT, WIDTH]\n",
    "    #image = tf.image_resize_images(image, size)\n",
    "    image.set_shape([HEIGHT, WIDTH, CHANNEL])\n",
    "    \n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255.0\n",
    "    \n",
    "    images_batch = tf.train.shuffle_batch([image],\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          num_threads= 12,\n",
    "                                          capacity = 200 + 3*BATCH_SIZE,\n",
    "                                          min_after_dequeue = 200)\n",
    "    num_images = len(images)\n",
    "    \n",
    "    return images_batch, num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4-Gh3lu7eM-C"
   },
   "outputs": [],
   "source": [
    "def generator(input, random_dim, is_train, reuse=False):\n",
    "    c4, c8, c16, c32, c64 = 512, 256, 128, 64, 32 # channel num\n",
    "    s4 = 4\n",
    "    output_dim = CHANNEL  # RGB image\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        with tf.variable_scope('gen') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "            w1 = tf.get_variable('w1', shape=[random_dim, s4 * s4 * c4], dtype=tf.float32,\n",
    "                                 initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b1 = tf.get_variable('b1', shape=[c4 * s4 * s4], dtype=tf.float32,\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "            flat_conv1 = tf.add(tf.matmul(input, w1), b1, name='flat_conv1')\n",
    "             #Convolution, bias, activation, repeat! \n",
    "            conv1 = tf.reshape(flat_conv1, shape=[-1, s4, s4, c4], name='conv1')\n",
    "            bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n",
    "            act1 = tf.nn.relu(bn1, name='act1')\n",
    "            # 8*8*256\n",
    "            #Convolution, bias, activation, repeat! \n",
    "            conv2 = tf.layers.conv2d_transpose(act1, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                               kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                               name='conv2')\n",
    "            bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "            act2 = tf.nn.relu(bn2, name='act2')\n",
    "            # 16*16*128\n",
    "            conv3 = tf.layers.conv2d_transpose(act2, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                               kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                               name='conv3')\n",
    "            bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "            act3 = tf.nn.relu(bn3, name='act3')\n",
    "            # 32*32*64\n",
    "            conv4 = tf.layers.conv2d_transpose(act3, c32, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                               kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                               name='conv4')\n",
    "            bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "            act4 = tf.nn.relu(bn4, name='act4')\n",
    "            # 64*64*32\n",
    "            conv5 = tf.layers.conv2d_transpose(act4, c64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                               kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                               name='conv5')\n",
    "            bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n",
    "            act5 = tf.nn.relu(bn5, name='act5')\n",
    "\n",
    "            #128*128*3\n",
    "            conv6 = tf.layers.conv2d_transpose(act5, output_dim, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                               kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                               name='conv6')\n",
    "            # bn6 = tf.contrib.layers.batch_norm(conv6, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn6')\n",
    "            act6 = tf.nn.tanh(conv6, name='act6')\n",
    "            return act6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qSnxcg_QeM-K"
   },
   "outputs": [],
   "source": [
    "def discriminator(input, is_train, reuse=False):\n",
    "    c2, c4, c8, c16 = 64, 128, 256, 512  # channel num: 64, 128, 256, 512\n",
    "    \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        with tf.variable_scope('dis') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            #Convolution, activation, bias, repeat! \n",
    "            conv1 = tf.layers.conv2d(input, c2, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                     name='conv1')\n",
    "            bn1 = tf.contrib.layers.batch_norm(conv1, is_training = is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope = 'bn1')\n",
    "            act1 = lrelu(conv1, n='act1')\n",
    "             #Convolution, activation, bias, repeat! \n",
    "            conv2 = tf.layers.conv2d(act1, c4, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                     name='conv2')\n",
    "            bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "            act2 = lrelu(bn2, n='act2')\n",
    "            #Convolution, activation, bias, repeat! \n",
    "            conv3 = tf.layers.conv2d(act2, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                     name='conv3')\n",
    "            bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "            act3 = lrelu(bn3, n='act3')\n",
    "             #Convolution, activation, bias, repeat! \n",
    "            conv4 = tf.layers.conv2d(act3, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                     name='conv4')\n",
    "            bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "            act4 = lrelu(bn4, n='act4')\n",
    "\n",
    "            # start from act4\n",
    "            dim = int(np.prod(act4.get_shape()[1:]))\n",
    "            fc1 = tf.reshape(act4, shape=[-1, dim], name='fc1')\n",
    "\n",
    "\n",
    "            w2 = tf.get_variable('w2', shape=[fc1.shape[-1], 1], dtype=tf.float32,\n",
    "                                 initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "            b2 = tf.get_variable('b2', shape=[1], dtype=tf.float32,\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "            # wgan just get rid of the sigmoid\n",
    "            logits = tf.add(tf.matmul(fc1, w2), b2, name='logits')\n",
    "            # dcgan\n",
    "            acted_out = tf.nn.sigmoid(logits)\n",
    "            return logits #, acted_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KATGuu23eM-S"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    random_dim = 100\n",
    "    \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        with tf.variable_scope('input'):\n",
    "            #real and fake image placholders\n",
    "            real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
    "            random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n",
    "            is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "    # wgan\n",
    "    fake_image = generator(random_input, random_dim, is_train)\n",
    "    \n",
    "    real_result = discriminator(real_image, is_train)\n",
    "    fake_result = discriminator(fake_image, is_train, reuse=True)\n",
    "    \n",
    "    d_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(real_result)  # This optimizes the discriminator.\n",
    "    g_loss = -tf.reduce_mean(fake_result)  # This optimizes the generator.\n",
    "            \n",
    "\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if 'dis' in var.name]\n",
    "    g_vars = [var for var in t_vars if 'gen' in var.name]\n",
    "    # test\n",
    "    # print(d_vars)\n",
    "    trainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list=d_vars)\n",
    "    trainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list=g_vars)\n",
    "    # clip discriminator weights\n",
    "    d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]\n",
    "\n",
    "    \n",
    "    batch_size = BATCH_SIZE\n",
    "    image_batch, samples_num = process_images()\n",
    "    \n",
    "    batch_num = int(samples_num / batch_size)\n",
    "    total_batch = 0\n",
    "    sess = tf.Session(config = config)\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # continue training\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")    \n",
    "    ckpt = tf.train.latest_checkpoint('./model/' + version)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    print('total training sample num:%d' % samples_num)\n",
    "    print('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\n",
    "    print('start training...')\n",
    "    for i in range(EPOCH):\n",
    "        print(i)\n",
    "        for j in range(batch_num):\n",
    "            print(j)\n",
    "            d_iters = 5\n",
    "            g_iters = 1\n",
    "\n",
    "            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            for k in range(d_iters):\n",
    "                #print(k)\n",
    "                train_image = sess.run(image_batch)\n",
    "                #wgan clip weights\n",
    "                sess.run(d_clip)\n",
    "                \n",
    "                # Update the discriminator\n",
    "                _, dLoss = sess.run([trainer_d, d_loss],\n",
    "                                    feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n",
    "\n",
    "            # Update the generator\n",
    "            for k in range(g_iters):\n",
    "                # train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "                _, gLoss = sess.run([trainer_g, g_loss],\n",
    "                                    feed_dict={random_input: train_noise, is_train: True})\n",
    "\n",
    "            # print 'train:[%d/%d],d_loss:%f,g_loss:%f' % (i, j, dLoss, gLoss)\n",
    "            \n",
    "        # save check point every 500 epoch\n",
    "        if i%500 == 0:\n",
    "            if not os.path.exists('./model/' + version):\n",
    "                os.makedirs('./model/' + version)\n",
    "                print(\"Directory made\")\n",
    "            saver.save(sess, './model/' +version + '/' + str(i))  \n",
    "        if i%50 == 0:\n",
    "            # save images\n",
    "            if not os.path.exists(new_logo_path):\n",
    "                os.makedirs(new_logo_path)\n",
    "                print(\"Directory made\")\n",
    "            sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n",
    "            # imgtest = imgtest * 255.0\n",
    "            # imgtest.astype(np.uint8)\n",
    "            save_images(imgtest, [8,8] ,new_logo_path + '/epoch' + str(i) + '.jpg')\n",
    "            \n",
    "            print('train:[%d],d_loss:%f,g_loss:%f' % (i, dLoss, gLoss))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BEQjQxFdeM-e"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "d4Eo7up1S20G",
    "outputId": "7c2c3047-b0a3-4b1b-d378-bf0188ee22d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "total training sample num:4368\n",
      "batch size: 64, batch num per epoch: 68, epoch num: 5000\n",
      "start training...\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "13\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "16\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "17\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "18\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "21\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "22\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "24\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "25\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "26\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "27\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "28\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "29\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "30\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "33\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "34\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "35\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "36\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "37\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "38\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "39\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "40\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "41\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "42\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "43\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "44\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "45\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "46\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "47\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "48\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "50\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "51\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "52\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "53\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "54\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "55\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "56\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "57\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "58\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "59\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "60\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "61\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "62\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "63\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "64\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "65\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "66\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "67\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "train:[0],d_loss:-371.434143,g_loss:192.920532\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "13\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "16\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "17\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "18\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "21\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "22\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "24\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "25\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "26\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "27\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "28\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "29\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "30\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "31\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "33\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "34\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "35\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "36\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "37\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "38\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "39\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "40\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "41\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "42\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "43\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "44\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "45\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "46\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "47\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "48\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "50\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "51\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "52\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "53\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "54\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "55\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "56\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "57\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "58\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "59\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "60\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "61\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "62\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "63\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "64\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "65\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "66\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "67\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "13\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "16\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "17\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "18\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "21\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "22\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-b7ac7cffb047>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[1;31m# Update the discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 _, dLoss = sess.run([trainer_d, d_loss],\n\u001b[1;32m---> 68\u001b[1;33m                                     feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;31m# Update the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1522699680956,
     "user": {
      "displayName": "Milos Mladenovic",
      "photoUrl": "//lh6.googleusercontent.com/-dA-JXATW86A/AAAAAAAAAAI/AAAAAAAAc6Q/qx8-ALBybj0/s50-c-k-no/photo.jpg",
      "userId": "102493204324592635873"
     },
     "user_tz": -120
    },
    "id": "rDnUAL36-KCI",
    "outputId": "23d0ccf5-af1f-49e0-8177-803d16cc4b07"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(new_logo_path):\n",
    "  print(\"doesnt exist\")\n",
    "  os.makedirs(new_logo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eZ_LfPtGeM-u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "logoGAN_tf.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
